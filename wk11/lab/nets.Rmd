---
title: "Lab week 11 - Neural nets and deep learning"
subtitle: "Data Science and Machine Learning 2 - CEU 2018"
author: "Jeno Pal"
date: '2018-03-20'
output:
  html_document:
    df_print: paged
  html_notebook:
    df_print: paged
---

```{r, message=FALSE}
library(ISLR)
library(data.table)
library(caret)
library(skimr)
library(ROCR)
```

## Neural nets with `caret`

Very large number of parameters: regularization is needed. Done via
ideas similar to ridge or lasso. (Hence it is a good idea to
center and scale features and remove correlated features / de-correlate 
them. Concrete example here: many binary features, then it
may not help much).

Also, typically local solutions
are found: initialization from many random starting values and model
averaging can help.

```{r}
# the famous german credit data
# downloaded in friendly form from
# https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/credit.csv
data <- fread("../../data/german_credit/german_credit.csv")
skim(data)
```
```{r}
data[, default := factor(ifelse(default == 1, "No", "Yes"))]

# turn character variables to factors
character_variables <- names(data)[sapply(names(data),
                                          function(x) is.character(data[[x]]))]
data <- data[, 
             (character_variables) := lapply(.SD, as.factor), 
             .SDcols = character_variables]
  
```

```{r}
training_ratio <- 0.75 
set.seed(1234)
train_indices <- createDataPartition(y = data[["default"]],
                                     times = 1,
                                     p = training_ratio,
                                     list = FALSE)
data_train <- data[train_indices, ]
data_test <- data[-train_indices, ]
```

```{r}
train_control <- trainControl(method = "cv",
                              number = 10,
                              classProbs = TRUE,
                              summaryFunction = twoClassSummary)
```

```{r}
# baseline logistic model
set.seed(857)
glm_model <- train(default ~ .,
                   method = "glm",
                   data = data_train,
                   trControl = train_control,
                   # preProcess = c("center", "scale", "pca"),
                   metric = "ROC")
glm_model
```

Size: number of units in the hidden layer. Decay: regularization parameter.
```{r}
tune_grid <- expand.grid(size = c(3, 5, 10, 15),
                         decay = c(0.1, 0.5, 1, 1.2))

set.seed(857)
nnet_model <- train(default ~ .,
                   method = "nnet",
                   data = data_train,
                   trControl = train_control,
                   tuneGrid = tune_grid,
                   metric = "ROC",
                   # avoid extensive iteration output
                   trace = FALSE)
nnet_model
```
```{r}
nnet_prediction <- prediction(predict.train(nnet_model, 
                                            newdata = data_test,
                                            type = "prob")$Yes,
                              data_test[["default"]])
performance(nnet_prediction, measure = "auc")@y.values[[1]]
```

`nnet` with different random initial seeds. (Default: 5 initial seeds, training takes
5x times with the same grid. Parameter `repeats` controls the number of seeds.)
```{r}
# takes a long time to run for the whole grid above
tune_grid <- expand.grid(size = c(5),
                         decay = c(0.5),
                         bag = FALSE)

set.seed(857)
avnnet_model <- train(default ~ .,
                   method = "avNNet",
                   data = data_train,
                   trControl = train_control,
                   tuneGrid = tune_grid,
                   metric = "ROC",
                   # avoid extensive iteration output
                   trace = FALSE)
avnnet_model
```

```{r}
avnnet_prediction <- prediction(predict.train(avnnet_model, 
                                            newdata = data_test,
                                            type = "prob")$Yes,
                              data_test[["default"]])
performance(avnnet_prediction, measure = "auc")@y.values[[1]]
```

## Deep learning with `h2o`

"Deep": many layers of hidden units. 

Note on estmiation: when having large datasets, k-fold cross validation can become
computationally burdensome, hence many times train/validation/test approach is used.
(see answer on Quora by Yoshua Bengio, one of the originators of deep learning [here](https://www.quora.com/Is-cross-validation-heavily-used-in-deep-learning-or-is-it-too-expensive-to-be-used)). However, cross validation can still be used
to tune some of the hyperparameters.

```{r}
library(h2o)
h2o.init(nthreads=-1)
```

```{r}
data <- h2o.importFile("../../data/airlines/airline100K.csv")

# take 10% as training set to speed up computations
data_split <- h2o.splitFrame(data, ratios = c(0.1, 0.4), seed = 123)
data_train <- data_split[[1]]
data_valid <- data_split[[2]]
data_test <- data_split[[3]]

y <- "dep_delayed_15min"
X <- setdiff(names(data_train), y)
```

Validation frame: used to determine early stopping conditions. More on this later.

```{r}
dl_model <- h2o.deeplearning(x = X, 
                             y = y, 
                             training_frame = data_train, 
                             validation_frame = data_valid,
                             # reproducible = TRUE,  # makes training slower but makes it reproducible
                             seed = 123)
h2o.performance(dl_model, data_test)@metrics$AUC
```

```{r}
h2o.scoreHistory(dl_model)
```

There are lots of parameters that you can change, see `?h2o.deeplearning`
and the [docs](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/deep-learning.html). Some selected parameters:

Network structure and functional form

* `hidden`: neuron layer architecture: length of vector shows
number of layers, number shows number of neurons within layer.
The default: two hidden layers with 200-200 neurons. Makes sense to
experiment with shallower but more neuron or with deeper and less neurons
per layer architectures.

```{r}
shallow_small_model <- h2o.deeplearning(x = X, 
                             y = y, 
                             training_frame = data_train, 
                             validation_frame = data_valid,
                             hidden = c(10),
                             seed = 123)
h2o.performance(shallow_small_model, data_test)@metrics$AUC
```
```{r}
shallow_large_model <- h2o.deeplearning(x = X, 
                             y = y, 
                             training_frame = data_train, 
                             validation_frame = data_valid,
                             hidden = c(512),
                             seed = 123)
h2o.performance(shallow_large_model, data_test)@metrics$AUC
```

```{r}
deep_small_model <- h2o.deeplearning(x = X, 
                             y = y, 
                             training_frame = data_train, 
                             validation_frame = data_valid,
                             hidden = c(32, 32, 32, 32, 32),
                             seed = 123)
h2o.performance(deep_small_model, data_test)@metrics$AUC
```

```{r}
deep_large_model <- h2o.deeplearning(x = X, 
                             y = y, 
                             training_frame = data_train, 
                             validation_frame = data_valid,
                             hidden = c(100, 100, 100),
                             seed = 123)
h2o.performance(deep_large_model, data_test)@metrics$AUC
```



* `activation`: the nonlinear transformative function used. Default: Rectifier.

```{r}
tanh_model <- h2o.deeplearning(x = X, 
                 y = y, 
                 training_frame = data_train, 
                 validation_frame = data_valid,
                 hidden = c(32, 32, 32, 32, 32),
                 activation = "Tanh",
                 seed = 123)
h2o.performance(tanh_model, data_test)@metrics$AUC
```


Training samples

* `epochs`: how many times will all training datapoints be used
to adjust the model in the course of the optimization (note: early
stopping is used by default so there is no guarantee that
all epochs will be used).

* `mini_batch_size`: after how many training samples is the
gradient update made (defaults to 1)

```{r}
more_epochs_model <- h2o.deeplearning(x = X, 
                 y = y, 
                 training_frame = data_train, 
                 validation_frame = data_valid,
                 hidden = c(32, 32, 32, 32, 32),
                 epochs = 20,
                 seed = 123)
h2o.performance(more_epochs_model, data_test)@metrics$AUC
```

```{r}
higher_batch_size_model <- h2o.deeplearning(x = X, 
                 y = y, 
                 training_frame = data_train, 
                 validation_frame = data_valid,
                 hidden = c(32, 32, 32, 32, 32),
                 mini_batch_size = 10,
                 seed = 123)
h2o.performance(higher_batch_size_model, data_test)@metrics$AUC
```

Regularization

* `hidden_dropout_ratios`: with how large probability will neurons
be left out of the model at a step (defaults to 0.5). Have to use
"WithDropout" activation to use dropout.

```{r}
dropout_model <- h2o.deeplearning(x = X, 
                 y = y, 
                 training_frame = data_train, 
                 validation_frame = data_valid,
                 hidden = c(32, 32, 32, 32, 32),
                 activation = "RectifierWithDropout",
                 hidden_dropout_ratios = c(0.1, 0.1, 0.2, 0.2, 0.2),
                 seed = 123)
h2o.performance(dropout_model, data_test)@metrics$AUC
```

* `input_dropout_ratio`: drop some input features randomly

```{r}
input_dropout_model <- h2o.deeplearning(x = X, 
                 y = y, 
                 training_frame = data_train, 
                 validation_frame = data_valid,
                 hidden = c(32, 32, 32, 32, 32),
                 input_dropout_ratio = 0.4,
                 seed = 123)
h2o.performance(input_dropout_model, data_test)@metrics$AUC
```

For more on dropout, see the original paper [here](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf).

* `l1`, `l2`: weight on $L1$ (lasso), $L2$ (ridge) penalty terms

```{r}
regularized_model <- h2o.deeplearning(x = X, 
                 y = y, 
                 training_frame = data_train, 
                 validation_frame = data_valid,
                 hidden = c(32, 32, 32, 32, 32),
                 l1 = 0.001,
                 l2 = 0.001,
                 seed = 123)
h2o.performance(regularized_model, data_test)@metrics$AUC
```

* early stopping options: `stopping_rounds`, `stoppnig_metric`, `stopping_tolerance`

Training constantly tracks validation frame performance. Early stopping is enabled
by default but can be tuned when to stop. This, again, is to prevent overfitting.
(If you don't supply a `validation_frame`, early stopping still works but based on 
metrics calculated from the training set = may not be as informative for out of sample
performance.)

```{r}
early_stopping_model <- h2o.deeplearning(x = X, 
                 y = y, 
                 training_frame = data_train, 
                 validation_frame = data_valid,
                 hidden = c(32, 32, 32, 32, 32),
                 epochs = 100,
                 stopping_rounds = 2,
                 stopping_metric = "AUC",
                 stopping_tolerance = 0.01,
                 seed = 123)
h2o.performance(early_stopping_model, data_test)@metrics$AUC
```

